{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05a8e5e0",
   "metadata": {},
   "source": [
    "# Forecast verification\n",
    "This is the main notebook of the study containing all the skill assessments.\n",
    "\n",
    "* **Most use seasonal averages for verification. How to best aggregate data? Needed in daily resolution for hindcast. Initial timestep of model = 20 mins (correct?)... if I aggregate to seasonal averages I could have just as well downloaded the monthly aggregated data firsthand and not bothered with the large daily dataset... how can daily data be considered in the analysis?**\n",
    "* see \"Effective Sample Size\" -> should I use it? see https://doi.org/10.1175/1520-0442(1999)012<1990:TENOSD>2.0.CO;2  Also compute the p values! Understand how this is used in forecast verification!\n",
    "\n",
    "* Check more verification datasets in one HindcastEnsemble? [Note](https://youtu.be/EcMxImmMBec?t=8526) more than one verification dataset can be carried along! This allows to compare the skill for multiple observational datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Misc TODO\n",
    "\n",
    "## Climpred things\n",
    "* Make sure that your init and lead dimensions align.* --> maybe I need to have the same number of init dates as lead timesteps. Try the xarray align method??? See https://climpred.readthedocs.io/en/stable/quick-start.html\n",
    "* Check: [Note](https://youtu.be/EcMxImmMBec?t=8647) a skill dimension is appended to the HindcastEnsemble object which allows to compare the skills of the forecast product and the skill of the reference forecast (e.g. persistence) -> good plot of the spatial distribution of skill in two rows, one for the forecast product and the other one for the reference product\n",
    "* --> just not sure how e.g. the ACC is computed then if we are not even in anomaly space. Does climpred actually compute anomalies?\n",
    "\n",
    "## EOF analysis\n",
    "* compute the EOFs\n",
    "    * https://ajdawson.github.io/eofs/latest/\n",
    "    * read Wilks chapter\n",
    "\n",
    "## Detrending\n",
    "* https://climpred.readthedocs.io/en/stable/api/climpred.stats.rm_poly.html#climpred.stats.rm_poly\n",
    "    * or better in XCLIM or straight away in Xarray?\n",
    "    * see here: https://youtu.be/SKXUBD6DGao?t=563\n",
    "* I will probably not need to worry about detrending at seasonal timescales... where is literature which specifies at which time intervals detrending becomes relevant? Do I need to justify?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # set up a local dask cluster for parallelisation and accessing the dashboard\n",
    "# from dask.distributed import Client, LocalCluster\n",
    "# cluster = LocalCluster()  # Launches a scheduler and workers locally\n",
    "# client = Client(cluster)  # Connect to distributed cluster and override default\n",
    "# # client = Client(address=\"127.0.0.1:8787\")\n",
    "# client"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sb123\\.conda\\envs\\Thesis2\\lib\\site-packages\\climpred\\classes.py:987: UserWarning: HindcastEnsemble is chunked along dimensions ['init'] with more than one chunk. `HindcastEnsemble.chunks=Frozen({'init': (1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), 'member': (25,), 'latitude': (9,), 'longitude': (11,), 'lead': (215,)})`.\n",
      "You cannot call `HindcastEnsemble.verify` or `HindcastEnsemble.bootstrap` in combination with any of  ['init'] passed as `dim`. In order to do so, please rechunk ['init'] with `HindcastEnsemble.chunk({{dim:-1}}).verify(dim=dim).`\n",
      "If you do not want to use dimensions  ['init'] in `HindcastEnsemble.verify(dim=dim)`, you can disregard this warning.\n",
      "Consider chunking embarassingly parallel dimensions such as ['longitude', 'latitude'] automatically, i.e. `HindcastEnsemble.chunk(longitude=\"auto\").verify(...).\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'function' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 8\u001B[0m\n\u001B[0;32m      2\u001B[0m hindcast \u001B[38;5;241m=\u001B[39m HindcastEnsemble(hc)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# hindcast = hindcast.add_observations(obs)\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Testing only:\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# hc = hc.assign_coords({\"month\" : hc.init.dt.month.values}) # for testing to\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# filter for inits on a specific month to compare results against https://meteoswiss-climate.shinyapps.io/skill_metrics/\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[43mhindcast\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupby\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mvalid_time.season\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mmean()\n",
      "File \u001B[1;32m~\\.conda\\envs\\Thesis2\\lib\\site-packages\\climpred\\classes.py:698\u001B[0m, in \u001B[0;36mPredictionEnsemble.__getattr__.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    695\u001B[0m                 warnings\u001B[38;5;241m.\u001B[39mwarn(msg)\n\u001B[0;32m    696\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m v\n\u001B[1;32m--> 698\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_apply_xr_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Thesis2\\lib\\site-packages\\climpred\\classes.py:746\u001B[0m, in \u001B[0;36mPredictionEnsemble._apply_func\u001B[1;34m(self, func, *args, **kwargs)\u001B[0m\n\u001B[0;32m    744\u001B[0m             datasets\u001B[38;5;241m.\u001B[39mupdate({key: func(ds, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)})\n\u001B[0;32m    745\u001B[0m \u001B[38;5;66;03m# Instantiates new object with the modified datasets.\u001B[39;00m\n\u001B[1;32m--> 746\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_construct_direct\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdatasets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkind\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkind\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Thesis2\\lib\\site-packages\\climpred\\classes.py:712\u001B[0m, in \u001B[0;36mPredictionEnsemble._construct_direct\u001B[1;34m(cls, datasets, kind)\u001B[0m\n\u001B[0;32m    710\u001B[0m obj\u001B[38;5;241m.\u001B[39m_datasets \u001B[38;5;241m=\u001B[39m datasets\n\u001B[0;32m    711\u001B[0m obj\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;241m=\u001B[39m kind\n\u001B[1;32m--> 712\u001B[0m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_warn_if_chunked_along_init_member_time\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    713\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj\n",
      "File \u001B[1;32m~\\.conda\\envs\\Thesis2\\lib\\site-packages\\climpred\\classes.py:946\u001B[0m, in \u001B[0;36mPredictionEnsemble._warn_if_chunked_along_init_member_time\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    939\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    940\u001B[0m \u001B[38;5;124;03mWarn when ``CLIMPRED_DIMS`` except ``lead`` are wrongly chunked.\u001B[39;00m\n\u001B[0;32m    941\u001B[0m \n\u001B[0;32m    942\u001B[0m \u001B[38;5;124;03mWhen more than one chunk to show how to circumvent ``xskillscore`` chunking\u001B[39;00m\n\u001B[0;32m    943\u001B[0m \u001B[38;5;124;03m``ValueError``.\u001B[39;00m\n\u001B[0;32m    944\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    945\u001B[0m suggest_one_chunk \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 946\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunks:\n\u001B[0;32m    947\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minit\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmember\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m    948\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunks[d]) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "\u001B[1;31mTypeError\u001B[0m: 'function' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Testing only:\n",
    "# hc = hc.assign_coords({\"month\" : hc.init.dt.month.values}) # for testing to\n",
    "# filter for inits on a specific month to compare results against https://meteoswiss-climate.shinyapps.io/skill_metrics/\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "convert_init_lead_to_valid_time_lead(hindcast.get_initialized())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Doing some visualisations and plausibility checks on our climpred\n",
    "# HindcastEnsemble\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "data = hindcast.get_observations().tp.values.flat\n",
    "# import numpy as np\n",
    "data[np.where(data < 0)[0]]\n",
    "\n",
    "# sns.histplot(data=hindcast.get_observations().tp.values[:,0,0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%time\n",
    "#\n",
    "verification_e2o = hindcast.verify(\n",
    "    metric=\"pearson_r\", comparison=\"e2o\", dim=\"init\", alignment=\"same_inits\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "verification_e2o"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Check, do I still have a member dimension when verifying with m2o?**\n",
    "\n",
    "**ToDo:** Also calculate the p - values and research the underlying\n",
    "methodology (see Wilks 2019)\n",
    "\n",
    "Da lÃ¤uft noch was schief mit den Verification Alignments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    ncols=2, figsize=(10, 5), subplot_kw={\"projection\": ccrs.PlateCarree()}\n",
    ")\n",
    "verification.sel({\"lead\": 1})[\"tp\"].plot(ax=ax[0], vmin=0, vmax=0.6)\n",
    "verification.sel({\"lead\": 100})[\"tp\"].plot(ax=ax[1], vmin=0, vmax=0.6)\n",
    "\n",
    "for ax in ax.flatten():\n",
    "    ax.add_feature(cfeature.BORDERS)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "verification.dims"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "y = verification.tp.sel({\"longitude\": 5, \"latitude\": 55}).values\n",
    "x = verification.lead.values\n",
    "ax.plot(x, y)\n",
    "fig.show()\n",
    "\n",
    "# TODO compute manually and compare the graphs!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "verification.tp.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "verification.tp.sel({\"lead\": 30}).plot(ax=ax)\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "verification.tp.sel({\"lead\": 30})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
